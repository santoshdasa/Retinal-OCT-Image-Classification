# -*- coding: utf-8 -*-
"""Retinal images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y0fX0UlRYbe2X3_eHeTxKWHwsVKbRGPv
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import keras
import os
from tqdm import tqdm
import tensorflow as tf
import pandas as pd
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras import backend as K
from sklearn.model_selection import train_test_split

"""## Loading the Data"""

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
import os
import pickle
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

listed = drive.ListFile({'q': "title contains 'X1.pickle' and '1c5L0BGU2S_OOX6YHxyDniITvfyS2KH5N' in parents"}).GetList()
for file in listed:
  print('title {}, id {}'.format(file['title'], file['id']))
  
  
from googleapiclient.discovery import build
drive_service = build('drive', 'v3')

import io
import pickle
from googleapiclient.http import MediaIoBaseDownload

file_id = '1c5L0BGU2S_OOX6YHxyDniITvfyS2KH5N'

request = drive_service.files().get_media(fileId=file_id)
downloaded = io.BytesIO()
downloader = MediaIoBaseDownload(downloaded, request)
done = False
while done is False:
    # _ is a placeholder for a progress object that we ignore.
    # (Our file is small, so we skip reporting progress.)
    _, done = downloader.next_chunk()

downloaded.seek(0)
X = pickle.load(downloaded)

X.shape

from googleapiclient.discovery import build
drive_service = build('drive', 'v3')

import io
import pickle
from googleapiclient.http import MediaIoBaseDownload

file_id = '16o6DwBb5DxtyWd4STw0NTHPItfzlknaC'

request = drive_service.files().get_media(fileId=file_id)
downloaded = io.BytesIO()
downloader = MediaIoBaseDownload(downloaded, request)
done = False
while done is False:
    # _ is a placeholder for a progress object that we ignore.
    # (Our file is small, so we skip reporting progress.)
    _, done = downloader.next_chunk()

downloaded.seek(0)
Y = pickle.load(downloaded)

"""## Data Splitting"""

(X1,Y1)=(X[:25000],Y[:25000])
x_train,x_test,y_train,y_test = train_test_split(X1,Y1,train_size=0.75,test_size=0.25)

x_train.shape[0]

x_test.shape[0]

plt.title("Test Distribution")
sns.countplot(y_test)
plt.show()

plt.title("Train Distribution")
sns.countplot(y_train)
plt.show()



"""### Declaring some useful variables"""

IMG_SIZE = 64
batch_size = 64
num_classes = 4
epochs = 10
input_shape = (IMG_SIZE,IMG_SIZE,1)
# convert class vectors to binary class matrices

y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

x_test = tf.keras.utils.normalize(x_test)
x_train = tf.keras.utils.normalize(x_train)

"""### 3 x 3 kernel (1-conv layer,1 maxpool)"""

model = Sequential()
model.add(Conv2D(128, kernel_size=(3, 3), activation='relu',input_shape=input_shape))

model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64,kernel_size=(3, 3),activation='relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

model.add(Flatten())

model.add(Dense(64, activation='relu'))

model.add(Dense(num_classes, activation='softmax'))
model.compile( loss='categorical_crossentropy' , optimizer='adam' , metrics=["accuracy"])

history= model.fit(x_train, y_train, batch_size=batch_size, epochs=10, verbose=1, validation_data=(x_test, y_test))

score = model.evaluate(x_test, y_test, verbose=0)

# this function is used to update the plots for each epoch and error
import matplotlib.pyplot as plt
def plt_dynamic(x, vy, ty, ax, colors=['b']):
    ax.plot(x, vy, 'b', label="Validation Loss")
    ax.plot(x, ty, 'r', label="Train Loss")
    plt.legend()
    plt.grid()
    fig.canvas.draw()
    plt.show()

print('Test score:', score[0]) 
print('Test accuracy:', score[1])

fig,ax = plt.subplots(1,1)
ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')
x = list(range(1,11))

vy = history.history['val_loss']
ty = history.history['loss']
plt_dynamic(x, vy, ty, ax)
plt.show()

from sklearn.metrics import confusion_matrix
pred= model.predict(x_test)
pred_classes = pred.argmax(axis=-1)

"""## Model2"""





